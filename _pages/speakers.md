---
layout: splash
permalink: /speakers/
---
# Talks

### Robin Cooper (Gothenburg University)<br/> [How to play games with types](/papers/cooper.pdf)
We present a theory of type acts based on type theory relating to a general theory of action which can be used as a foundation for a theory of linguistic acts.

### Heather Burnett (LLF, Paris-Diderot)<br/> [Identity construction in dialogue: A game-theoretic approach]()
(TBA)

### Nicholas Asher  (IRIT, Toulouse)<br/> (TBA)                                                                                                                       

### Ye Tian (LLF, Paris-Diderot & Amazon)<br/> [Um, what’s the word: Filled Pauses and Self-addressed Questions; Disfluency in German, French and Chinese dialogues](/papers/tian.pdf)
There is an ongoing debate whether phenomena of disfluency (such as filled pauses) are produced communicatively. Clark and Fox Tree (Cognition 84(1):73–111, 2002) propose that filled pauses are words, and that different forms signal different lengths of delay. This paper evaluates this Filler-As-Words hypothesis by analyzing the distribution of self-addressed-questions or SAQs (such as “what’s the word”) in relation to filled pauses. We found that SAQs address different problems in different languages (most frequently about memory-retrieval in English and Chinese, and about appropriateness in Japanese). In relation to filled pauses, British but not American English uses “um” to signal a more severe problem than “uh”. Chinese uses different filled pauses to signal the syntactic category of the problem constituent. Japanese uses different filled pauses to signal levels of interaction with the interlocuter. Overall, our data supports the Filler-As-Words hypothesis that filled pauses are used communicatively. However, the dimensions of its meanings vary across languages and dialects.

### Julian Hough (Bielefeld University)<br/> [Deep Learning Approaches to Incremental Disfluency Detection](/papers/hough.pdf)
We present the joint task of incremental disfluency detection and utterance segmentation and a simple deep learning system which performs it on transcripts and ASR results. We show how the constraints of the two tasks interact. Our joint-task system outperforms the equivalent individual task systems, provides competitive results and is suitable for future use in conversation agents in the psychiatric domain.

### Andrzej Wisniewski (Adam Mickiewicz University, Poznan)<br/>[Question dependencies in view of erotetic logic]()
(TBA)

### David Traum (ICT, USC)<br/> [Multi-floor dialogue and hybrid requests]()
(TBA)

### David Schlangen (Bielefeld University)<br/>[Dialogical Learning and Maintenance of a Lexicon for Situated Interaction](/papers/schlangen.pdf)
Meaningful language use rests on the grounding of the language in the non-linguistic world and in the practices of language users. This grounding is built up and maintained in interaction, through Conversational Grounding, which is the interactive process with which interlocutors build mutual understanding; Justification, the ability to explain and provide reasons for one’s language use; and Adaptation, the ability to accept corrections and adapt future language use accordingly. We outline a model of grounded semantics that combines perceptual knowledge (how to visually identify potential referents of terms; realised as classifiers taking visual information as input) and taxonomic knowledge (covering lexical relations such as hyponymy and hypernymy), and we sketch a proof-of-concept implementation of a dialogue system that realises the interactional skills that ground this knowledge.

### Chiara Mazzocconi (LLF, Paris-Diderot)<br/> [What’s your laughter doing there?]()
(TBA)

### Andy Lücking (Frankfurt University)<br/> [From exemplification, through alignment to association: Aspects of iconic gesture meaning](/papers/luecking.pdf)                            
In natural language face to face communication interlocutors exploit manifold non-verbal information resources, most notably hand and arm movements, i.e. gestures. In this paper, a type-theoretical approach using Type Theory with Records is introduced which accounts for iconic gestures within an information state update semantics. Iconic gestures are semantically exploited in two steps: firstly, their kinetic representations are mapped onto vector sequence representations from vector space semantics, modeling a perceptual gesture classification; secondly, these vectorial representations are linked to linguistic predicates, giving rise to a computational account to semantic-kinematic interfaces. Each of the steps involves reasoning processes, which are made explicit. The resulting framework shows how various resources have to be integrated in the update mechanism in order to deal with apparently simple multimodal utterances.

### Judith Holler (MPI, Nijmegen)<br/> [Multimodal language use and comprehension in social interaction: the body is part of the package](/papers/holler.pdf)
The home of human language use is face-to-face interaction, a context in which communicative exchanges are characterised not only by bodily signals accompanying what is being said but also by a pattern of alternating turns at talk. This transition between turns is astonishingly fast—typically a mere 200-ms elapse between a current and a next speaker’s contribution—meaning that comprehending, producing, and coordinating conversational contributions in time is a significant challenge. This begs the question of whether the additional information carried by bodily signals facilitates or hinders language processing in this time-pressured environment. We present analyses of multimodal conversations revealing that bodily signals appear to profoundly influence language processing in interaction: Questions accompanied by gestures lead to shorter turn transition times—that is, to faster responses—than questions without gestures, and responses come earlier when gestures end before compared to after the question turn has ended. These findings hold even after taking into account prosodic patterns and other visual signals, such as gaze. The empirical findings presented here provide a first glimpse of the role of the body in the psycholinguistic processes underpinning human communication.

### Ian Cross (Cambridge University)<br/> [Music, speech and the relational dimension of interaction](/papers/cross.pdf)
Mainstream operationalisations of music in contemporary digital culture tend to take forms that fit with Western folk-theoretic conceptions of music: as discrete sonic entities—songs, pieces, works—that fall within an autonomous domain of human experience, that have determinate structure and that have both affective and exchange value. This perspective is problematised in alternative digital manifestations of music as constituted in and through interaction, in which music is emergent from interactive processes that are computationally mediated. This alternative digital approach fits with broad conceptions of music that are grounded in ethnomusicological accounts and that have increasing weight in the cognitive sciences, in which music is understood and explored as a communicative medium. This paper will outline some of the possibilities, potentials and problems for digital approaches that are likely to arise in operationalising music as communicative interaction.

### Jonathan Ginzburg (LLF, Paris-Diderot)<br/> [Gesture, Emotion and Interaction]()     
(TBA)
